{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debnathch/nlp_fakenewsSymantic/blob/main/Fake_News_Detection_Starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR-ZUkwJrFn"
      },
      "source": [
        "# Fake News Detection\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXeHUV5fJGiZ"
      },
      "source": [
        "## Objective\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX73YZdgJIgF"
      },
      "source": [
        "The objective of this assignment is to develop a Semantic Classification model. You will be using Word2Vec method to extract the semantic relations from the text and develop a basic understanding of how to train supervised models to categorise text based on its meaning, rather than just syntax. You will explore how this technique is used in situations where understanding textual meaning plays a critical role in making accurate and efficient decisions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Business Objective\n",
        "\n",
        "The spread of fake news has become a significant challenge in today’s digital world. With the massive volume of news articles published daily, it’s becoming harder to distinguish between credible and misleading information. This creates a need for systems that can automatically classify news articles as true or fake, helping to reduce misinformation and protect public trust.\n",
        "\n",
        "\n",
        "In this assignment, you will develop a Semantic Classification model that uses the Word2Vec method to detect recurring patterns and themes in news articles. Using supervised learning models, the goal is to build a system that classifies news articles as either fake or true.\n"
      ],
      "metadata": {
        "id": "Gg_J6K8Xxfk2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySqxOckxI4-F"
      },
      "source": [
        "<h2> Pipelines that needs to be performed </h2>\n",
        "\n",
        "You need to perform the following tasks to complete the assignment:\n",
        "\n",
        "<ol type=\"1\">\n",
        "\n",
        "  <li> Data Preparation\n",
        "  <li> Text Preprocessing\n",
        "  <li> Train Validation Split\n",
        "  <li> EDA on Training Data\n",
        "  <li> EDA on Validation Data [Optional]\n",
        "  <li> Feature Extraction\n",
        "  <li> Model Training and Evaluation\n",
        "\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTxV-3GJUhWm"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofebI8ITG-Li"
      },
      "source": [
        "**NOTE:** The marks given along with headings and sub-headings are cumulative marks for those particular headings/sub-headings.<br>\n",
        "\n",
        "The actual marks for each task are specified within the tasks themselves.\n",
        "\n",
        "For example, marks given with heading *2* or sub-heading *2.1* are the cumulative marks, for your reference only. <br>\n",
        "\n",
        "The marks you will receive for completing tasks are given with the tasks.\n",
        "\n",
        "Suppose the marks for two tasks are: 3 marks for 2.1.1 and 2 marks for 3.2.2, or\n",
        "* 2.1.1 [3 marks]\n",
        "* 3.2.2 [2 marks]\n",
        "\n",
        "then, you will earn 3 marks for completing task 2.1.1 and 2 marks for completing task 3.2.2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdQjht7dUiHt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b1lNTpKF54T"
      },
      "source": [
        "## Data Dictionary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43j_A_GsI9TS"
      },
      "source": [
        "For this assignment, you will work with two datasets, `True.csv` and `Fake.csv`.\n",
        "Both datasets contain three columns:\n",
        "<ul>\n",
        "  <li> title of the news article\n",
        "  <li> text of the news article\n",
        "  <li> date of article publication\n",
        "</ul>\n",
        "\n",
        "`True.csv` dataset includes 21,417 true news, while the `Fake.csv` dataset comprises 23,502 fake news."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oTQwQ_Rh4nT"
      },
      "source": [
        "## Installing required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "lIY57QOLiCA2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade numpy==1.26.4\n",
        "# !pip install --upgrade pandas==2.2.2\n",
        "# !pip install --upgrade nltk==3.9.1\n",
        "# !pip install --upgrade spacy==3.7.5\n",
        "# !pip install --upgrade scipy==1.12\n",
        "# !pip install --upgrade pydantic==2.10.5\n",
        "# !pip install wordcloud==1.9.4\n",
        "# !python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuLFIymAL58u"
      },
      "source": [
        "## Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "O-Q9pqrcJrFr"
      },
      "outputs": [],
      "source": [
        "# Import essential libraries for data manipulation and analysis\n",
        "import numpy as np  # For numerical operations and arrays\n",
        "import pandas as pd  # For working with dataframes and structured data\n",
        "import re  # For regular expression operations (text processing)\n",
        "import nltk  # Natural Language Toolkit for text processing\n",
        "import spacy  # For advanced NLP tasks\n",
        "import string  # For handling string-related operations\n",
        "\n",
        "# Optional: Uncomment the line below to enable GPU support for spaCy (if you have a compatible GPU)\n",
        "#spacy.require_gpu()\n",
        "\n",
        "# Load the spaCy small English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# For data visualization\n",
        "import seaborn as sns  # Data visualization library for statistical graphics\n",
        "import matplotlib.pyplot as plt  # Matplotlib for creating static plots\n",
        "# Configure Matplotlib to display plots inline in Jupyter Notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Suppress unnecessary warnings to keep output clean\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# For interactive plots\n",
        "from plotly.offline import plot  # Enables offline plotting with Plotly\n",
        "import plotly.graph_objects as go  # For creating customizable Plotly plots\n",
        "import plotly.express as px  # A high-level interface for Plotly\n",
        "\n",
        "# For preprocessing and feature extraction in machine learning\n",
        "from sklearn.feature_extraction.text import (  # Methods for text vectorization\n",
        "    CountVectorizer,  # Converts text into a bag-of-words model\n",
        ")\n",
        "\n",
        "# Import accuracy, precision, recall, f_score from sklearn to predict train accuracy\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Pretty printing for better readability of output\n",
        "from pprint import pprint\n",
        "\n",
        "# For progress tracking in loops (useful for larger datasets)\n",
        "from tqdm import tqdm, tqdm_notebook  # Progress bar for loops\n",
        "tqdm.pandas()  # Enables progress bars for pandas operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "s8Le3OfjI666"
      },
      "outputs": [],
      "source": [
        "## Change the display properties of pandas to max\n",
        "# pd.set_option('display.max_colwidth', None)\n",
        "# pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtRLCsNVJrFt"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "Load the True.csv and Fake.csv files as DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "puVzIf_iJrFt"
      },
      "outputs": [],
      "source": [
        "# Import the first file - True.csv\n",
        "true_df = pd.read_csv(\"True.csv\")\n",
        "# Import the second file - Fake.csv\n",
        "fake_df = pd.read_csv('Fake.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xYpH-sAJrFu"
      },
      "source": [
        "## **1.** Data Preparation  <font color = red>[10 marks]</font>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2fTeYJImEv7"
      },
      "source": [
        "### **1.0** Data Understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Lf8ufHH5JrFu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db92463d-e781-4132-8bb0-11b554b7a363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21417 entries, 0 to 21416\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   title   21417 non-null  object\n",
            " 1   text    21417 non-null  object\n",
            " 2   date    21417 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 502.1+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Inspect the DataFrame with True News to understand the given data\n",
        "\n",
        "print(true_df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "gI7X0Voh6h7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531ab528-4516-4a2c-d44f-a920d7b36465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23523 entries, 0 to 23522\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   title   23502 non-null  object\n",
            " 1   text    23502 non-null  object\n",
            " 2   date    23481 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 551.4+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Inspect the DataFrame with Fake News to understand the given data\n",
        "print(fake_df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "Dwcty-wmJrFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcc24f49-a48d-488e-a1d7-0e059cec0e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0  As U.S. budget fight looms, Republicans flip t...   \n",
            "1  U.S. military to accept transgender recruits o...   \n",
            "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
            "3  FBI Russia probe helped by Australian diplomat...   \n",
            "4  Trump wants Postal Service to charge 'much mor...   \n",
            "\n",
            "                                                text                date  \n",
            "0  WASHINGTON (Reuters) - The head of a conservat...  December 31, 2017   \n",
            "1  WASHINGTON (Reuters) - Transgender people will...  December 29, 2017   \n",
            "2  WASHINGTON (Reuters) - The special counsel inv...  December 31, 2017   \n",
            "3  WASHINGTON (Reuters) - Trump campaign adviser ...  December 30, 2017   \n",
            "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  December 29, 2017   \n",
            "                                                   title  \\\n",
            "21412  'Fully committed' NATO backs new U.S. approach...   \n",
            "21413  LexisNexis withdrew two products from Chinese ...   \n",
            "21414  Minsk cultural hub becomes haven from authorities   \n",
            "21415  Vatican upbeat on possibility of Pope Francis ...   \n",
            "21416  Indonesia to buy $1.14 billion worth of Russia...   \n",
            "\n",
            "                                                    text              date  \n",
            "21412  BRUSSELS (Reuters) - NATO allies on Tuesday we...  August 22, 2017   \n",
            "21413  LONDON (Reuters) - LexisNexis, a provider of l...  August 22, 2017   \n",
            "21414  MINSK (Reuters) - In the shadow of disused Sov...  August 22, 2017   \n",
            "21415  MOSCOW (Reuters) - Vatican Secretary of State ...  August 22, 2017   \n",
            "21416  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...  August 22, 2017   \n"
          ]
        }
      ],
      "source": [
        "# Print the column details for True News DataFrame\n",
        "print(true_df.head())\n",
        "print(true_df.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "EPLAnUMjjzQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d31729-1583-4535-88cf-c161f47ca6a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
            "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
            "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
            "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
            "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
            "\n",
            "                                                text               date  \n",
            "0  Donald Trump just couldn t wish all Americans ...  December 31, 2017  \n",
            "1  House Intelligence Committee Chairman Devin Nu...  December 31, 2017  \n",
            "2  On Friday, it was revealed that former Milwauk...  December 30, 2017  \n",
            "3  On Christmas day, Donald Trump announced that ...  December 29, 2017  \n",
            "4  Pope Francis used his annual Christmas Day mes...  December 25, 2017  \n",
            "                                                   title  \\\n",
            "23518  McPain: John McCain Furious That Iran Treated ...   \n",
            "23519  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
            "23520  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n",
            "23521  How to Blow $700 Million: Al Jazeera America F...   \n",
            "23522  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
            "\n",
            "                                                    text              date  \n",
            "23518  21st Century Wire says As 21WIRE reported earl...  January 16, 2016  \n",
            "23519  21st Century Wire says It s a familiar theme. ...  January 16, 2016  \n",
            "23520  Patrick Henningsen  21st Century WireRemember ...  January 15, 2016  \n",
            "23521  21st Century Wire says Al Jazeera America will...  January 14, 2016  \n",
            "23522  21st Century Wire says As 21WIRE predicted in ...  January 12, 2016  \n"
          ]
        }
      ],
      "source": [
        "# Print the column details for Fake News Dataframe\n",
        "print(fake_df.head())\n",
        "print(fake_df.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "dyuDFzPkI67B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea90eea9-78aa-47f4-fecf-bfc5d8c2ad5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['title', 'text', 'date'], dtype='object')\n",
            "Index(['title', 'text', 'date'], dtype='object')\n",
            "title    object\n",
            "text     object\n",
            "date     object\n",
            "dtype: object\n",
            "title    object\n",
            "text     object\n",
            "date     object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Print the column names of both DataFrames\n",
        "print(fake_df.columns)\n",
        "print(true_df.columns)\n",
        "\n",
        "print(fake_df.dtypes)\n",
        "print(true_df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2fff1S7hq5h"
      },
      "source": [
        "### **1.1** Add new column  <font color = red>[3 marks]</font> <br>\n",
        "\n",
        "Add new column `news_label` to both the DataFrames and assign labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "YOu_KhbH78du"
      },
      "outputs": [],
      "source": [
        "# Add a new column 'news_label' to the true news DataFrame and assign the label \"1\" to indicate that these news are true\n",
        "true_df['news_label'] = 1\n",
        "# Add a new column 'news_label' to the fake news DataFrame and assign the label \"0\" to indicate that these news are fake\n",
        "fake_df['news_label'] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UShuo3h54DAh"
      },
      "source": [
        "### **1.2** Merge DataFrames  <font color = red>[2 marks]</font> <br>\n",
        "\n",
        "Create a new Dataframe by merging True and Fake DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "5GX_QMy04M4-"
      },
      "outputs": [],
      "source": [
        "# Combine the true and fake news DataFrames into a single DataFrame\n",
        "\n",
        "combined_df = pd.concat([true_df, fake_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "FYCtKXD1JrFw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a496f113-a4ca-41f8-e907-313677078652"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  As U.S. budget fight looms, Republicans flip t...   \n",
              "1  U.S. military to accept transgender recruits o...   \n",
              "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
              "3  FBI Russia probe helped by Australian diplomat...   \n",
              "4  Trump wants Postal Service to charge 'much mor...   \n",
              "\n",
              "                                                text                date  \\\n",
              "0  WASHINGTON (Reuters) - The head of a conservat...  December 31, 2017    \n",
              "1  WASHINGTON (Reuters) - Transgender people will...  December 29, 2017    \n",
              "2  WASHINGTON (Reuters) - The special counsel inv...  December 31, 2017    \n",
              "3  WASHINGTON (Reuters) - Trump campaign adviser ...  December 30, 2017    \n",
              "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  December 29, 2017    \n",
              "\n",
              "   news_label  \n",
              "0           1  \n",
              "1           1  \n",
              "2           1  \n",
              "3           1  \n",
              "4           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5ba2969-627f-407f-8ef3-d75ff07be22c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>news_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
              "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U.S. military to accept transgender recruits o...</td>\n",
              "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
              "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
              "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
              "      <td>December 30, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
              "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5ba2969-627f-407f-8ef3-d75ff07be22c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c5ba2969-627f-407f-8ef3-d75ff07be22c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c5ba2969-627f-407f-8ef3-d75ff07be22c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c33c38e8-0b8f-4415-b773-3300e1950e73\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c33c38e8-0b8f-4415-b773-3300e1950e73')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c33c38e8-0b8f-4415-b773-3300e1950e73 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df",
              "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 44940,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38740,\n        \"samples\": [\n          \"U.S. Treasury adds cash management measures due to debt limit\",\n          \" You\\u2019re Not Going To Believe What Trump Just Stopped A Press Conference For (VIDEO)\",\n          \"Hispanic coalition asks Trump to stop 'attacks'\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38657,\n        \"samples\": [\n          \"It turns out that there are a few new reasons for Wisconsin to proceed with their recount, and they have nothing to do with Jill Stein s recount petition. Yes, she filed the petition and yes, she paid the fee, but the state needed to do this even without Stein s request. A new analysis in the Washington Post discovered significant voting anomalies in several wards.Trump now leads Hillary by just over 22,000 votes in Wisconsin. The WaPo analysis didn t look at precincts or counties   they looked at wards, which are the smallest unit where votes are counted. This helped create a more detailed picture of what s happening there.Walter Mebane, an associate researcher at the Center for Political Studies and a professor of political science and statistics at the University of Michigan, looked at small wards that used optical scanning technology, and found that certain features in the vote tabulations reveal the possibility that these counts were tampered with.For instance, using a method called  last digit diagnostics,  Mebane found that the tabulations he looked at should have last digits that, when averaged together, show a mean of around 4.5. Lower could mean that the counts were manipulated.In the small wards he looked at where optical scanning tech was used, the last digit diagnostics reveal a mean average much lower than 4.5.Another statistic Mebane looked at was how often the last digit of a vote tabulation was zero, or five. If there are no problems, then the mean average of that variable should be around 0.2. Larger could mean someone was sloppy, and smaller could mean votes were manipulated.In these small wards, that number was significantly smaller than .2 for Hillary, meaning that the vote counts show a last digit of zero or five far less often than they should.He also found evidence of something called  signaling  in the tabulations, which is when fraudsters leave a type of trail that more or less claims credit for the fraud. Mebane points out that this is actually a fairly common tactic amongst fraudsters in Russia.Finally, a simple test revealed something called  multimodality,  which could show that someone was receiving fraudulent votes. These small wards exhibited that anomaly, too.None of this is absolute proof of election fraud or vote fraud in Wisconsin, and Mebane is careful to note that. However, it gives credence to the need for a recount, whatever Jill Stein s motivations are. If nothing else, conducting a thorough recount will lend further legitimacy to our democratic process or concretely reveal problems that need to be fixed. It might also serve to weaken Trump s efforts to undermine our democracy by repeatedly crying  FRAUD!! FRAUD EVERYWHERE!! The recount begins today.Featured image by Darren Hauck via Getty Images\",\n          \"WASHINGTON (Reuters) - Saudi Arabia\\u2019s Deputy Crown Prince Mohammed bin Salman and U.S. President Donald Trump agreed in a meeting on Tuesday that Iran represents a regional security threat, a senior adviser to the deputy crown prince said The adviser also said the talks marked a \\u201chistorical turning point\\u201d in U.S.-Saudi relations. Saudi Arabia had viewed with unease the administration of U.S. President Barack Obama, whom they felt considered Riyadh\\u2019s alliance with Washington less important than negotiating a nuclear deal with Iran in 2015. It has been encouraged by the Trump administration\\u2019s hardline stance on Iran and its nuclear program. \\u201cThe meeting today restored issues to their right path and form a big change in relations between both countries in political, military, security and economic issues,\\u201d the senior adviser said in a statement. \",\n          \"SEOUL (Reuters) - U.S. Secretary of State Rex Tillerson flew to Asia accompanied by only one journalist on his aircraft, a reporter from a website founded by former Republican political operatives, in a departure from decades of practice. Tillerson, who became the top U.S. diplomat under  Republican President Donald Trump in February, traveled to Mexico and Germany last month with a small contingent of journalists, including a \\u201cpool\\u201d reporter who informed colleagues of Tillerson\\u2019s statements or actions. The journalist on Tillerson\\u2019s plane that arrived in Tokyo on Wednesday, Erin McPike of the Independent Journal Review (IJR), was not acting as a pool reporter. State Department Acting Spokesman Mark Toner said in a statement that there was only one seat available on Tillerson\\u2019s plane for media. The department had previously told reporters covering Tillerson\\u2019s trip to South Korea, Japan, and China that he would not be taking reporters on his plane and that they would have to fly commercially, breaking with decades of precedent stretching back to Henry Kissinger. \\u201cIt was decided to take a journalist from an outlet that doesn\\u2019t normally travel with the Secretary of State, as part of an effort to include a broader representation of U.S. media,\\u201d Toner said. \\u201cWe will also make every effort to include a contingent of media on the Secretary\\u2019s plane going forward.\\u201d The State Department originally said that Tillerson could not accommodate the usual contingent of reporters because of space constraints. It also said the decision to travel without reporters was intended to cut costs. News organizations pay the U.S. government for the cost of their travel. The journalists who reported Tillerson\\u2019s landing in Tokyo on Wednesday evening traveled there on commercial flights. Depending on the number of staff Tillerson chose to take to Asia, the Boeing 737 he traveled on could likely have accommodated more than one reporter. The conservative-leaning IJR said in a statement late on Tuesday that the State Department last week offered the seat on Tillerson\\u2019s plane. McPike is a White House correspondent for IJR, and previously reported for CNN, Real Clear Politics, NBC News, and National Journal, according to IJR\\u2019s website when she joined in February. She was also briefly part of the team that covered the 2016 election campaign for Reuters. \\u201cWe don\\u2019t take this opportunity lightly and recognize the controversy surrounding press access for the trip,\\u201d IJR founder and chief executive Alex Skatell said in a statement. In 2014, Skatell told The New York Times he wanted to start a site after observing a gap in reaching \\u201ca more mainstream center-right audience.\\u201d The State Department Correspondents\\u2019 Association said in a statement that it was \\u201cdisappointed\\u201d Tillerson chose to travel to Asia without a full contingent of media \\u201cor even a pool reporter\\u201d and called for access to Tillerson equal to that given by the reporter on the plane during his trip to Asia. Tillerson, a former chief executive with the Exxon Mobil oil  company, faces a tough first trip to Asia seeking to reassure nervous allies facing North Korea\\u2019s growing nuclear and missile threat and press China to do more on perhaps the most serious security challenge confronting Trump. For decades, secretaries of state have nearly always invited media to travel with them. In rare cases, particularly late in a secretary\\u2019s tenure, some news outlets have declined, such as former Secretary John Kerry\\u2019s December 2016 trip to Saudi Arabia. Republican secretaries of state Alexander Haig, George Shultz, James Baker, and Condoleezza Rice routinely took 10 or more journalists on their overseas trips, even to war zones. Before founding IJR, Skatell worked for the National Republican Senatorial Committee and for the Republican Governors Association, according to his LinkedIn profile. Another founder, Phil Musser, was once executive director of the Republican Governors Association and worked in the Department of Housing and Urban Development in the administration of George W. Bush.  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2408,\n        \"samples\": [\n          \"Oct 29, 2015\",\n          \"Nov 12, 2015\",\n          \"March 1, 2016\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"news_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "# Display the first 5 rows of the combined DataFrame to verify the result\n",
        "combined_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IphUaBu3oFZK"
      },
      "source": [
        "### **1.3** Handle the null values  <font color = red>[2 marks]</font> <br>\n",
        "\n",
        "Check for null values and handle it by imputation or dropping the null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "4FRDxOo6r51j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "5cfa60d3-764b-4792-f4fb-6abbb805e856"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title         21\n",
              "text          21\n",
              "date          42\n",
              "news_label     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>news_label</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "# Check Presence of Null Values\n",
        "combined_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "eiwvoyfYr6EB"
      },
      "outputs": [],
      "source": [
        "# Handle Rows with Null Values\n",
        "combined_df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDyPvMITooWA"
      },
      "source": [
        "### **1.4** Merge the relevant columns and drop the rest from the DataFrame  <font color = red>[3 marks]</font> <br>\n",
        "\n",
        "Combine the relevant columns into a new column `news_text` and then drop irrelevant columns from the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "u9VI48jS_HTy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7ad14359-18dd-4aff-c9a8-858d1488d717"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           news_text\n",
              "0  As U.S. budget fight looms, Republicans flip t...\n",
              "1  U.S. military to accept transgender recruits o...\n",
              "2  Senior U.S. Republican senator: 'Let Mr. Muell...\n",
              "3  FBI Russia probe helped by Australian diplomat...\n",
              "4  Trump wants Postal Service to charge 'much mor..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9a27b18-ea75-4514-bcce-002b42ec7e6b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U.S. military to accept transgender recruits o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9a27b18-ea75-4514-bcce-002b42ec7e6b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c9a27b18-ea75-4514-bcce-002b42ec7e6b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c9a27b18-ea75-4514-bcce-002b42ec7e6b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6ab26574-b0e9-4572-bb08-3282bf6a1419\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ab26574-b0e9-4572-bb08-3282bf6a1419')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6ab26574-b0e9-4572-bb08-3282bf6a1419 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df",
              "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 44898,\n  \"fields\": [\n    {\n      \"column\": \"news_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39105,\n        \"samples\": [\n          \" This Church Treasurer Is Going To Jail For A Crime Spree That Blows The Lie Of \\u2018Christian Morality\\u2019 Apart (VIDEO) A church treasurer from Ohio is going to jail for five years after blowing $800,000 of church funds on a decade-long drugs and sex rampage. So much for that  Christian Morality  that Evangelicals argue makes them better than people of other faiths and none.61-year-old Garry Meyer was the trusted treasurer of Tri-County Baptist Church in West Chester Township, Ohio for 14 years. What his church did not know, is that he was actually cooking the books, spending nearly a million dollars of church money on drugs, lavish holidays, expensive cars, pornography and  high end  escorts for more than a decade.While maintaining the pretense of a god-fearing, responsible, married father, Meyer lived a rock star lifestyle on the side   and his church community picked up the tab.But, sadly for Meyer, his wife uncovered the crime. Under pressure, he made a confession to the church. The only problem was, he  confessed  to stealing $400,000. Once the full investigation was complete, Meyer was exposed as a liar all over again. The full sum stolen was twice that figure.Meyer s wife sobbed in the courtroom as her husband s exploits were exposed, and he was sentenced to five years in prison. He told the court: There is no excuse for my actions, I also want to say I am sorry to my family. I have caused unimaginable hurt and suffering, Turning to his wife, Meyer said: I am sorry for betraying your trust   you have always been the best part of my life. Meyer stole nearly a million dollars from his own congregation in order to fund a lifestyle to which his church is supposed to stand opposed. Also speaking at Meyer s sentancing hearing was colleague Pastor Brian McManus, who said: Our church family has continued to pray for everyone involved in this very sad event. The truth is, our life choices always come down to personal   not religious   morality. A person bent on making the wrong decisions in life, will do so with or without the bible. This lesson is everywhere   from child-abusing priests, to chumps like Garry Meyer, and on to so-called Christian Conservative leaders who lay the sin of wrath upon anyone who fails to follow their warped Ayn Randian version of God.Featured image via video screen capture\",\n          \"SENATOR FEINSTEIN Shocks CNN Anchor With \\u201cPrecise Answer\\u201d On Trump/Russia Smear Campaign [Video] What s all the fuss about if there s no there, there? Is anyone else sickened by the left s efforts to discredit President Trump for months when they knew there was NOTHING THERE!Feinstein had visited CIA headquarters on Tuesday and was briefed on the investigation but months before this we all knew the truth It s just that Feinstein finally admitted it:  Not at this time NOT AT THIS TIME???The Democrats owe President Trump the BIGGEST apology!THE FOLLOWING COMMENT EXPRESSES HOW AMERICA FEELS ABOUT FEINSTEIN AND HER CRONIES: It s been hundreds of days since the  Russian  smear campaign conducted by MSM, democrat operative morons like Olbermann and late night  comedians , and Clintons political cronies   and yet still nothing. Nothing. Not a single thing. A few more months and then they will quietly say  case closed  and hope and pray that we all forgot. Sorry but we won t and we watch you all very differently now, we see right through you. Our patience is just about out and your time handling our power is up. FEINSTEIN EMBARRASES HERSELF DURING QUESTIONING TO NEIL GORSUCH:Senator Dianne Feinstein is no match for Supreme Court nominee Neil Gorsuch. In her questioning today she really made a fool of herself when she tossed out a question that made it clear she hadn t done her homework on Gorsuch. He answered her question by citing numerous specific cases in his legal history. It s understandable that the Democrats are trying to play to their base by dragging out the process of asking ridiculous questions of this perfect nominee for the SCOTUS. This is embarrassing and we have two more days of it! It seems this is backfiring on the Democrats RETIRE ALREADY!\",\n          \"Hillary Clinton Supporters Now Calling for a Recount of Votes in Battleground States  The person who received the most votes free from interference or tampering needs to be in the White House. It may well be Donald J. Trump, but further due diligence is required to ensure that American democracy is not threatened. 21st Century Wire says Although the election was called on Nov 8th, the Democratic Party s ongoing campaign to delegitimize the new incoming President is still ongoing. For those of us with long enough memories, the Democratic Party, their media operatives and the Clinton Campaign were claiming that Trump and the GOP would be engaged in this very same behavior after Hillary Clinton won the Presidency (as expected).Notice how the shoe is now on the other foot.It s interesting reading past stories by  news  sources linked to the Clinton Campaign and John Podesta as Politico has, who ran a feature on Aug 16th entitled,  Why the GOP Will Never Accept President Hillary Clinton  which lays out the case of Hillary s lock on the White House and how the evil Republicans will not accept her eventual election victory. Will Donald Trump respect the peaceful transition of power?  howled CNN s Wolf Blitzer in the run-up to the election. The question now is: will the Democrats respect the result, and simply  Move On,  as they say?Of course, we now know that  journalists  like Wolf at CNN were getting their talking points directly the Clinton Campaign.As it turns out, the only thing illegitimate about the 2016 Election  was the mainstream corporate media. More form the Guardian  John Swane The GuardianA growing number of academics and activists are calling for US authorities to fully audit or recount the 2016 presidential election vote in key battleground states, in case the results could have been skewed by foreign hackers.The loose coalition, which is urging Hillary Clinton s campaign to join its fight, is preparing to deliver a report detailing its concerns to congressional committee chairs and federal authorities early next week, according to two people involved.The document, which is currently 18 pages long, focuses on concerns about the results in the states of Michigan, Pennsylvania and Wisconsin. I m interested in verifying the vote,  said Dr Barbara Simons, an adviser to the US election assistance commission and expert on electronic voting.  We need to have post-election ballot audits.  Simons is understood to have contributed analysis to the effort but declined to characterise the precise nature of her involvement.A second group of analysts, led by the National Voting Rights Institute founder John Bonifaz and Professor Alex Halderman, the director of the University of Michigan s center for computer security and society, is also taking part in the push for a review, and has been in contact with Simons.In a blogpost early on Wednesday, Halderman said paper ballots and voting equipment should be examined in Wisconsin, Michigan, and Pennsylvania, warning that deadlines were rapidly approaching. Unfortunately, nobody is ever going to examine that evidence unless candidates in those states act now, in the next several days, to petition for recounts,  he said.The developments follow Clinton s surprise defeat to Donald Trump in the 8 November vote, and come after US intelligence authorities released public assessments that Russian hackers were behind intrusions into regional electoral computer systems and the theft of emails from Democratic officials before the election Continue this article at The GuardianREAD MORE ELECTION NEWS AT: 21st Century Wire 2016 Files \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "# Combine the relevant columns into a new column 'news_text' by joining their values with a space\n",
        "combined_df['news_text'] = combined_df['title'] + ' ' + combined_df['text']\n",
        "# Drop the irrelevant columns from the DataFrame as they are no longer needed\n",
        "combined_df.drop(['title', 'text','date', 'news_label'], axis=1, inplace=True)\n",
        "# Display the first 5 rows of the updated DataFrame to check the result\n",
        "combined_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8cvHdJQitW8Y"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L944HZpsJrFy"
      },
      "source": [
        "## **2.** Text Preprocessing <font color = red>[15 marks]</font> <br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "On all the news text, you need to:\n",
        "<ol type=1>\n",
        "  <li> Make the text lowercase\n",
        "  <li> Remove text in square brackets\n",
        "  <li> Remove punctuation\n",
        "  <li> Remove words containing numbers\n",
        "</ol>\n",
        "\n",
        "\n",
        "Once you have done these cleaning operations you need to perform POS tagging and lemmatization on the cleaned news text, and remove all words that are not tagged as NN or NNS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-6VW3V3jx1A"
      },
      "source": [
        "### **2.1** Text Cleaning  <font color = red>[5 marks]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78OZs7P4kp41"
      },
      "source": [
        "#### 2.1.0 Create a new DataFrame to store the processed data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "uXnN7aa_JrF0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0e8b108-8e42-4b10-8a66-0a7e9bb58448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-9cc52386c329>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_tag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_tags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mwordnet_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_wordnet_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mlemma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwordnet_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mlemmas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-128-9cc52386c329>\u001b[0m in \u001b[0;36mget_wordnet_pos\u001b[0;34m(pos_tag)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mADV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Tokenize the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Download the 'averaged_perceptron_tagger_eng' resource if not already present\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# Create a DataFrame('df_clean') that will have only the cleaned news text and the lemmatized news text with POS tags removed\n",
        "def get_wordnet_pos(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = []\n",
        "df_clean_list = [] # Initialize an empty list to store processed data\n",
        "for text in combined_df['news_text']:\n",
        "  token = word_tokenize(text.lower())\n",
        "  # Initialize the WordNet lemmatizer\n",
        "  lemmatizer = nltk.WordNetLemmatizer()\n",
        "  #Define a function to map NLTK's POS tags to WordNet's\n",
        "  #Perform POS tagging\n",
        "  pos_tags = pos_tag(token)\n",
        "\n",
        "  #Lemmatize words with the correct POS\n",
        "  lemmas = []\n",
        "  for word, pos_tag in pos_tags:\n",
        "    wordnet_pos = get_wordnet_pos(pos_tag)\n",
        "    lemma = lemmatizer.lemmatize(word, pos=wordnet_pos)\n",
        "    lemmas.append(lemma)\n",
        "  #lemmatized text (without POS tags)\n",
        "  df_clean = \" \".join(lemmas)\n",
        "  df_clean_list.append({'news_text': df_clean})  # Append processed data to the list\n",
        "\n",
        "# Create a DataFrame from the processed data list\n",
        "df_clean = pd.DataFrame(df_clean_list)\n",
        "# Add 'news_label' column to the new dataframe for topic identification\n",
        "# df_clean.insert(1, 'news_label', combined_df['news_label']) #This line is incorrect. df_clean is a string\n",
        "\n",
        "print(df_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsf00J83mdNL"
      },
      "source": [
        "#### 2.1.1 Write the function to clean the text and remove all the unnecessary elements  <font color = red>[4 marks]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm7SjjSkJrFz"
      },
      "outputs": [],
      "source": [
        "# Write the function here to clean the text and remove all the unnecessary elements\n",
        "\n",
        "# Convert to lower case\n",
        "\n",
        "# Remove text in square brackets\n",
        "\n",
        "# Remove punctuation\n",
        "\n",
        "# Remove words with numbers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDFMNnrdkUvd"
      },
      "source": [
        "#### 2.1.2  Apply the function to clean the news text and store the cleaned text in a new column within the new DataFrame. <font color = red>[1 mark]</font> <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOiDVvEIJrF0"
      },
      "outputs": [],
      "source": [
        "# Apply the function to clean the news text and remove all unnecessary elements\n",
        "# Store it in a separate column in the new DataFrame\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSAVnSelkF9d"
      },
      "source": [
        "### **2.2** POS Tagging and Lemmatization  <font color = red>[10 marks]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCqNHDL2mHok"
      },
      "source": [
        "#### 2.2.1 Write the function for POS tagging and lemmatization, filtering stopwords and keeping only NN and NNS tags <font color = red>[8 marks]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgOu8t8HJrFz"
      },
      "outputs": [],
      "source": [
        "# Write the function for POS tagging and lemmatization, filtering stopwords and keeping only NN and NNS tags\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T3So7PXlibT"
      },
      "source": [
        "#### 2.2.2  Apply the POS tagging and lemmatization function to cleaned text and store it in a new column within the new DataFrame. <font color = red>[2 mark]</font> <br>\n",
        "\n",
        "**NOTE: Store the cleaned text and the lemmatized text with POS tags removed in separate columns within the new DataFrame.**\n",
        "\n",
        "**This will be useful for analysing character length differences between cleaned text and lemmatized text with POS tags removed during EDA.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9FWmibNI67F"
      },
      "outputs": [],
      "source": [
        "# Apply POS tagging and lemmatization function to cleaned text\n",
        "# Store it in a separate column in the new DataFrame\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMc5kjeqnX9b"
      },
      "source": [
        "### Save the Cleaned data as a csv file (Recommended)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTjNG5xfnlwm"
      },
      "outputs": [],
      "source": [
        "## Recommended to perform the below steps to save time while rerunning the code\n",
        "# df_clean.to_csv(\"clean_df.csv\", index=False)\n",
        "# df_clean = pd.read_csv(\"clean_df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0M0LseVjneMv"
      },
      "outputs": [],
      "source": [
        "# Check the first few rows of the DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDZq_T3FYuOi"
      },
      "outputs": [],
      "source": [
        "# Check the dimensions of the DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah1aJPmiAqWz"
      },
      "outputs": [],
      "source": [
        "# Check the number of non-null entries and data types of each column\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMzqKme_2QQ0"
      },
      "source": [
        "## **3.** Train Validation Split <font color = red>[5 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmx_W7Ty2PlK"
      },
      "outputs": [],
      "source": [
        "# Import Train Test Split and split the DataFrame into 70% train and 30% validation data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7Un1AElJrF2"
      },
      "source": [
        "## **4.** Exploratory Data Analysis on Training Data  <font color = red>[40 marks]</font> <br>\n",
        "\n",
        "Perform EDA on cleaned and preprocessed texts to get familiar with the training data by performing the tasks given below:\n",
        "\n",
        "<ul>\n",
        "  <li> Visualise the training data according to the character length of cleaned news text and lemmatized news text with POS tags removed\n",
        "  <li> Using a word cloud, find the top 40 words by frequency in true and fake news separately\n",
        "  <li> Find the top unigrams, bigrams and trigrams by frequency in true and fake news separately\n",
        "</ul>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOZ7yZ4Fp1cp"
      },
      "source": [
        "### **4.1** Visualise character lengths of cleaned news text and lemmatized news text with POS tags removed  <font color = red>[10 marks]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCI4DbZWpQ7n"
      },
      "source": [
        "##### 4.1.1  Add new columns to calculate the character lengths of the processed data columns  <font color = red>[3 marks]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HifHm5rxpaxZ"
      },
      "outputs": [],
      "source": [
        "# Add a new column to calculate the character length of cleaned news text\n",
        "\n",
        "# Add a new column to calculate the character length of lemmatized news text with POS tags removed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1JvT8lNpbFe"
      },
      "source": [
        "##### 4.1.2  Create Histogram to visualise character lengths  <font color = red>[7 marks]</font> <br>\n",
        "\n",
        " Plot both distributions on the same graph for comparison and to observe overlaps and peak differences to understand text preprocessing's impact on text length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-zaqJF6JrF2"
      },
      "outputs": [],
      "source": [
        "# Create a histogram plot to visualise character lengths\n",
        "\n",
        "# Add histogram for cleaned news text\n",
        "\n",
        "# Add histogram for lemmatized news text with POS tags removed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9jD_6SeJrF3"
      },
      "source": [
        "### **4.2** Find and display the top 40 words by frequency among true and fake news in Training data after processing the text  <font color = red>[10 marks]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n320yzDiEUH4"
      },
      "source": [
        "##### 4.2.1 Find and display the top 40 words by frequency among true news in Training data after processing the text  <font color = red>[5 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcfdvtfZJrF3"
      },
      "outputs": [],
      "source": [
        "## Use a word cloud find the top 40 words by frequency among true news in the training data after processing the text\n",
        "\n",
        "# Filter news with label 1 (True News) and convert to it string and handle any non-string values\n",
        "\n",
        "# Generate word cloud for True News\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbHtjWzbEj__"
      },
      "source": [
        "##### 4.2.2 Find and display the top 40 words by frequency among fake news in Training data after processing the text  <font color = red>[5 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOFoDEscEkMO"
      },
      "outputs": [],
      "source": [
        "## Use a word cloud find the top 40 words by frequency among fake news in the training data after processing the text\n",
        "\n",
        "# Filter news with label 0 (Fake News) and convert to it string and handle any non-string values\n",
        "\n",
        "# Generate word cloud for Fake News\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DfCSbbmJrF4"
      },
      "source": [
        "### **4.3** Find and display the top unigrams, bigrams and trigrams by frequency in true news and fake news after processing the text  <font color = red>[20 marks]</font> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApGagSppsAyL"
      },
      "source": [
        "##### 4.3.1 Write a function to get the specified top n-grams  <font color = red>[4 marks]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mbk5DS5JrF4"
      },
      "outputs": [],
      "source": [
        "# Write a function to get the specified top n-grams\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHcBL7vRsM4I"
      },
      "source": [
        "##### 4.3.2 Handle the NaN values  <font color = red>[1 mark]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ks69UQGCXpw"
      },
      "outputs": [],
      "source": [
        "# Handle NaN values in the text data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caioIgIEsfh2"
      },
      "source": [
        "### For True News\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYB2ZXZ83fjo"
      },
      "source": [
        "##### 4.3.3 Display the top 10 unigrams by frequency in true news and plot them as a bar graph  <font color = red>[2.5 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YX7fedm1JrF8"
      },
      "outputs": [],
      "source": [
        "# Print the top 10 unigrams by frequency in true news and plot the same using a bar graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3Q7wQnnsvOE"
      },
      "source": [
        "##### 4.3.4 Display the top 10 bigrams by frequency in true news and plot them as a bar graph  <font color = red>[2.5 marks]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aV7kD7w8JrF8"
      },
      "outputs": [],
      "source": [
        "# Print the top 10 bigrams by frequency in true news and plot the same using a bar graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opdM04-Bs_Bg"
      },
      "source": [
        "##### 4.3.5 Display the top 10 trigrams by frequency in true news and plot them as a bar graph  <font color = red>[2.5 marks]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xkh7vtbtJrF-"
      },
      "outputs": [],
      "source": [
        "# Print the top 10 trigrams by frequency in true news and plot the same using a bar graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prNx2Sm0WGEj"
      },
      "source": [
        "### For Fake News\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obBKlBVK3mfX"
      },
      "source": [
        "##### 4.3.6 Display the top 10 unigrams by frequency in fake news and plot them as a bar graph  <font color = red>[2.5 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qKDzoSIWGXp"
      },
      "outputs": [],
      "source": [
        "# Print the top 10 unigrams by frequency in fake news and plot the same using a bar graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSlMnmqcYsNw"
      },
      "source": [
        "##### 4.3.7 Display the top 10 bigrams by frequency in fake news and plot them as a bar graph  <font color = red>[2.5 marks]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5xUk_r9Wa0f"
      },
      "outputs": [],
      "source": [
        "# Print the top 10 bigrams by frequency in fake news and plot the same using a bar graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i08WYIwPYs6R"
      },
      "source": [
        "##### 4.3.8 Display the top 10 trigrams by frequency in fake news and plot them as a bar graph  <font color = red>[2.5 marks]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nT9a1EvWa-s"
      },
      "outputs": [],
      "source": [
        "# Print the top 10 trigrams by frequency in fake news and plot the same using a bar graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VsOO_oHN8-_"
      },
      "source": [
        "## **5.** Exploratory Data Analysis on Validation Data [Optional]\n",
        "\n",
        "Perform EDA on validation data to differentiate EDA on training data with EDA on validation data and the tasks are given below:\n",
        "\n",
        "<ul>\n",
        "  <li> Visualise the data according to the character length of cleaned news text and lemmatized text with POS tags removed\n",
        "  <li> Using a word cloud find the top 40 words by frequency in true and fake news separately\n",
        "  <li> Find the top unigrams, bigrams and trigrams by frequency in true and fake news separately\n",
        "</ul>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNkif5wrONfI"
      },
      "source": [
        "### **5.1** Visualise character lengths of cleaned news text and lemmatized news text with POS tags removed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAhwSWBWOTIj"
      },
      "source": [
        "##### 5.1.1  Add new columns to calculate the character lengths of the processed data columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hYYTrdHORAs"
      },
      "outputs": [],
      "source": [
        "# Add a new column to calculate the character length of cleaned news text\n",
        "\n",
        "# Add a new column to calculate the character length of lemmatized news text with POS tags removed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRILiD8hOX5q"
      },
      "source": [
        "##### 5.1.2  Create Histogram to visualise character lengths\n",
        "\n",
        "Plot both distributions on the same graph for comparison and to observe overlaps and peak differences to understand text preprocessing's impact on text length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7LLOXC0Oaix"
      },
      "outputs": [],
      "source": [
        "# Create a histogram plot to visualise character lengths\n",
        "\n",
        "# Add histogram for cleaned news text\n",
        "\n",
        "# Add histogram for lemmatized news text with POS tags removed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPxa0JrvOwFu"
      },
      "source": [
        "### **5.2** Find and display the top 40 words by frequency among true and fake news after processing the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOZRD8vaFt2h"
      },
      "source": [
        "##### 5.2.1  Find and display the top 40 words by frequency among true news in validation data after processing the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_9UVs4WOw0_"
      },
      "outputs": [],
      "source": [
        "## Use a word cloud find the top 40 words by frequency among true news after processing the text\n",
        "\n",
        "# Generate word cloud for True News\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6AQPITsFuop"
      },
      "source": [
        "##### 5.2.2  Find and display the top 40 words by frequency among fake news in validation data after processing the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gk6xTdSFu1X"
      },
      "outputs": [],
      "source": [
        "## Use a word cloud find the top 40 words by frequency among fake news after processing the text\n",
        "\n",
        "# Generate word cloud for Fake News\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx0s2a7xOxKf"
      },
      "source": [
        "### **5.3** Find and display the top unigrams, bigrams and trigrams by frequency in true news and fake news after processing the text  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2xZKU0RO5ft"
      },
      "source": [
        "##### 5.3.1 Write a function to get the specified top n-grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g70ZFxcoOxS2"
      },
      "outputs": [],
      "source": [
        "## Write a function to get the specified top n-grams\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8ud5-r7O7ut"
      },
      "source": [
        "##### 5.3.2 Handle the NaN values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsBu-aotPBJF"
      },
      "outputs": [],
      "source": [
        "## First handle NaN values in the text data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KVWcxoDPAiE"
      },
      "source": [
        "### For True News\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am3uuIlU4wj1"
      },
      "source": [
        "\n",
        "##### 5.3.3 Display the top 10 unigrams by frequency in true news and plot them as a bar graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKdpz-XmPGHD"
      },
      "outputs": [],
      "source": [
        "## Print the top 10 unigrams by frequency in true news and plot the same using a bar graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiKrOL8rPLAs"
      },
      "source": [
        "##### 5.3.4 Display the top 10 bigrams by frequency in true news and plot them as a bar graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuyYGnaNPLwq"
      },
      "outputs": [],
      "source": [
        "## Print the top 10 bigrams by frequency in true news and plot the same using a bar graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f8_h-BiPOKb"
      },
      "source": [
        "##### 5.3.5 Display the top 10 trigrams by frequency in true news and plot them as a bar graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lz-XS7qPQZj"
      },
      "outputs": [],
      "source": [
        "## Print the top 10 trigrams by frequency in true news and plot the same using a bar graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MfApeGrd6Fl"
      },
      "source": [
        "### For Fake News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CH1csmZeGqh"
      },
      "source": [
        "##### 5.3.6 Display the top 10 unigrams by frequency in fake news and plot them as a bar graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w310WzGAeG4K"
      },
      "outputs": [],
      "source": [
        "## Print the top 10 unigrams by frequency in fake news and plot the same using a bar graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFjOaPx7eHFw"
      },
      "source": [
        "##### 5.3.7 Display the top 10 bigrams by frequency in fake news and plot them as a bar graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuTqnjkIeHSJ"
      },
      "outputs": [],
      "source": [
        "## Print the top 10 bigrams by frequency in fake news and plot the same using a bar graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn_oiixheHf_"
      },
      "source": [
        "##### 5.3.8 Display the top 10 trigrams by frequency in fake news and plot them as a bar graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xduyO4gheHtI"
      },
      "outputs": [],
      "source": [
        "## Print the top 10 trigrams by frequency in fake news and plot the same using a bar graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-I0k0QtJrGA"
      },
      "source": [
        "## **6.** Feature Extraction  <font color = red>[10 marks]</font> <br>\n",
        "\n",
        "For any ML model to perform classification on textual data, you need to convert it to a vector form. In this assignment, you will use the Word2Vec Vectorizer to create vectors from textual data. Word2Vec model captures the semantic relationship between words.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09xy3mAbtZgZ"
      },
      "source": [
        "### **6.1** Initialise Word2Vec model  <font color = red>[2 marks]</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8fGwaCPJrGA",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "## Write your code here to initialise the Word2Vec model by downloading \"word2vec-google-news-300\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYzD85nTJrGA"
      },
      "source": [
        "### **6.2** Extract vectors for cleaned news data   <font color = red>[8 marks]</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffzdDpp_JrGB"
      },
      "outputs": [],
      "source": [
        "## Write your code here to extract the vectors from the Word2Vec model for both training and validation data\n",
        "\n",
        "\n",
        "## Extract the target variable for the training data and validation data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q9lwvNEJrGB"
      },
      "source": [
        "## **7.** Model Training and Evaluation <font color = red>[45 marks]</font>\n",
        "\n",
        "You will use a set of supervised models to classify the news into true or fake."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO16REK-xpq4"
      },
      "source": [
        "### **7.0** Import models and evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0BKoT3wxpq4"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLuHH1olZXQq"
      },
      "source": [
        "### **7.1** Build Logistic Regression Model  <font color = red>[15 marks]</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1ItmvvGwduv"
      },
      "source": [
        "##### 7.1.1 Create and train logistic regression model on training data  <font color = red>[10 marks]</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzXd3YSu5eyY"
      },
      "outputs": [],
      "source": [
        "## Initialise Logistic Regression model\n",
        "\n",
        "## Train Logistic Regression model on training data\n",
        "\n",
        "## Predict on validation data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvNKC8ob8IAL"
      },
      "source": [
        "##### 7.1.2 Calculate and print accuracy, precision, recall and f1-score on validation data <font color = red>[5 marks]</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEyQcSoWo4xs"
      },
      "outputs": [],
      "source": [
        "## Calculate and print accuracy, precision, recall, f1-score on predicted labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6P4MA_AC216"
      },
      "outputs": [],
      "source": [
        "# Classification Report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRGPMQZd8r8B"
      },
      "source": [
        "### **7.2** Build Decision Tree Model <font color = red>[15 marks]</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgv4vqrt81sH"
      },
      "source": [
        "##### 7.2.1 Create and train a decision tree model on training data <font color = red>[10 marks]</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-mTab94xpq4"
      },
      "outputs": [],
      "source": [
        "## Initialise Decision Tree model\n",
        "\n",
        "## Train Decision Tree model on training data\n",
        "\n",
        "## Predict on validation data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ_Vj5fs6w9I"
      },
      "source": [
        "##### 7.2.2 Calculate and print accuracy, precision, recall and f1-score on validation data <font color = red>[5 marks]</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15iYiCQhp7jo"
      },
      "outputs": [],
      "source": [
        "## Calculate and print accuracy, precision, recall, f1-score on predicted labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DohNckxxxpq4"
      },
      "outputs": [],
      "source": [
        "# Classification Report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnB_P9kd9EdC"
      },
      "source": [
        "### **7.3** Build Random Forest Model <font color = red>[15 marks]</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhW0nyU29In9"
      },
      "source": [
        "##### 7.3.1 Create and train a random forest model on training data <font color = red>[10 marks]</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIvY9-oPxpq4"
      },
      "outputs": [],
      "source": [
        "## Initialise Random Forest model\n",
        "\n",
        "## Train Random Forest model on training data\n",
        "\n",
        "## Predict on validation data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRBxZieM7eea"
      },
      "source": [
        " ##### 7.3.2 Calculate and print accuracy, precision, recall and f1-score on validation data <font color = red>[5 marks]</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzNK3jcCq01-"
      },
      "outputs": [],
      "source": [
        "## Calculate and print accuracy, precision, recall, f1-score on predicted labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIBCo_kFxpq4"
      },
      "outputs": [],
      "source": [
        "# Classification Report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8.** Conclusion <font color = red>[5 marks]</font>\n",
        "\n",
        "Summarise your findings by discussing patterns observed in true and fake news and how semantic classification addressed the problem. Highlight the best model chosen, the evaluation metric prioritised for the decision, and assess the approach and its impact."
      ],
      "metadata": {
        "id": "Lnj7RUDDSEJX"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}